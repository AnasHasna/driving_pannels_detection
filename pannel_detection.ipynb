{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 images traitées\n",
      "2000 images traitées\n",
      "3000 images traitées\n",
      "4000 images traitées\n",
      "5000 images traitées\n",
      "6000 images traitées\n",
      "7000 images traitées\n",
      "8000 images traitées\n",
      "9000 images traitées\n",
      "10000 images traitées\n",
      "11000 images traitées\n",
      "12000 images traitées\n",
      "13000 images traitées\n",
      "14000 images traitées\n",
      "15000 images traitées\n",
      "16000 images traitées\n",
      "17000 images traitées\n",
      "18000 images traitées\n",
      "19000 images traitées\n",
      "20000 images traitées\n",
      "21000 images traitées\n",
      "22000 images traitées\n",
      "23000 images traitées\n",
      "24000 images traitées\n",
      "25000 images traitées\n",
      "26000 images traitées\n",
      "27000 images traitées\n",
      "28000 images traitées\n",
      "29000 images traitées\n",
      "30000 images traitées\n",
      "31000 images traitées\n",
      "32000 images traitées\n",
      "33000 images traitées\n",
      "34000 images traitées\n",
      "35000 images traitées\n",
      "36000 images traitées\n",
      "37000 images traitées\n",
      "38000 images traitées\n",
      "39000 images traitées\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image # PIL est une bibliothèque Python qui permet d'ouvrir et de manipuler des images\n",
    "import numpy as np\n",
    "\n",
    "# Définir le chemin du dossier contenant les images du dataset\n",
    "dataset_folder = \"C:/Users/OMEN/Desktop/dataset/datasetTrafficSign/Train\"\n",
    "\n",
    "# Creer deux listes vides pour stocker les images et les labels\n",
    "X_train = []  \n",
    "Y_train = [] \n",
    "\n",
    "k = 0  # Compteur pour afficher le nombre d'images traitées\n",
    "\n",
    "# Traverser le dossier dataset_folder et ses sous-dossiers et fichiers en utilisant os.walk\n",
    "for root, dirs, files in os.walk(dataset_folder):\n",
    "    # root est le chemin du dossier actuel\n",
    "    # dirs est une liste des noms des sous-dossiers dans le dossier actuel\n",
    "    # files est une liste des noms des fichiers dans le dossier actuel\n",
    "    for filename in files:\n",
    "        # Check if the file has a .png extension\n",
    "        if filename.endswith(\".png\"):\n",
    "            # Ouvrir l'image, la convertir en niveaux de grille, la redimensionner en 28x28 pixels\n",
    "            image = Image.open(os.path.join(root, filename)).convert(\"L\").resize((28, 28))\n",
    "\n",
    "            # convertir les images en vecteurs de 784 éléments (28*28) et les stocker dans X_train et les labels dans Y_train\n",
    "            arr = np.array(image) / 255 # normaliser les valeurs des pixels entre 0 et 1 car les valeurs des pixels sont entre 0 et 255\n",
    "            vec = arr.reshape((784,)) \n",
    "            X_train.append(vec)\n",
    "            label = root[-1]  # on va assumer que le label est le dernier caractère du nom du dossier\n",
    "            Y_train.append(label)\n",
    "\n",
    "            k += 1\n",
    "            if k % 1000 == 0:\n",
    "                print(k, \"images traitées\")\n",
    "\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9672855879752431\n",
      "0.9080893603998776\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_train, Y_train) # Diviser le dataset en deux parties: train et test  (75% pour train et 25% pour test)\n",
    "mlp = MLPClassifier().fit(X_train, Y_train) # classification utilisant un Perceptron Multi-Couches \n",
    "print(mlp.score(X_train, Y_train)) #  affiche la précision du modèle sur l'ensemble d'entraînement.\n",
    "print(mlp.score(X_test, Y_test))  # affiche la précision du modèle sur l'ensemble de test.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C'est l'image du panneau de ne pas surpasser la vitesse 120km/h\n",
      "C'est l'image du panneau ne pas conduire a 80 km/h\n"
     ]
    }
   ],
   "source": [
    "def img_to_vec(path):\n",
    "    # Convertir l'image en niveaux de gris, la redimensionner à (28, 28) et normaliser les valeurs entre 0 et 1\n",
    "    img = Image.open(path).convert(\"L\").resize((28, 28))\n",
    "    arr = np.array(img) / 255\n",
    "    \n",
    "    # Aplatir l'array en un vecteur de dimension 784\n",
    "    vec = arr.reshape((784,))\n",
    "    return vec\n",
    "\n",
    "\n",
    "path = \"C:/Users/OMEN/Desktop/dataset/datasetTrafficSign/Train/8/00008_00001_00022.png\"\n",
    "image = Image.open(path)\n",
    "image.show()\n",
    "vec = img_to_vec(path)\n",
    "if(mlp.predict([vec]) == '8'):  \n",
    "    print(\"C'est l'image du panneau de ne pas surpasser la vitesse 120km/h\")\n",
    "\n",
    "path = \"C:/Users/OMEN/Desktop/dataset/datasetTrafficSign/Train/6/00006_00000_00026.png\"\n",
    "image = Image.open(path)\n",
    "image.show()\n",
    "vec = img_to_vec(path)\n",
    "if(mlp.predict([vec]) == '6'):\n",
    "    print(\"C'est l'image du panneau ne pas conduire a 80 km/h\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
